{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch1_1_Image_02_FinetuningTorchVisionModels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BigOyayubi/PyTorchTutorial/blob/master/PyTorch1_1_Image_02_FinetuningTorchVisionModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvP9bN2umSh",
        "colab_type": "text"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "TorchVisionモデル群をどのようにしてFineTuning/featureExtract(特徴抽出)していくかを学びます。\n",
        "\n",
        "FineTuningでは事前訓練済みモデルの全パラメータを更新します。\n",
        "FeatureExtractionでは事前訓練済みモデルの最終層重みのみ更新します。\n",
        "\n",
        "流れはどちらも同じように以下のようになります。\n",
        "\n",
        "\n",
        "*   事前訓練済みモデル初期化\n",
        "*   最終層（ら）の出力数を新しいデータセットの分類数に合わせる\n",
        "*   パラメータの最適化関数を用意\n",
        "*   学習\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxsB5EPXuSTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "71cb5d59-d1fb-40bc-d79c-5f50008d4de3"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.1.0\n",
            "Torchvision Version:  0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZC-qCUj0t5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46a6ee01-6952-4cda-9734-c14075f8f758"
      },
      "source": [
        "#学習用データのDL\n",
        "!wget --no-clobber https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip -f hymenoptera_data.zip -d data\n",
        "!ls -la data/hymenoptera_data/train/ants/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘hymenoptera_data.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  hymenoptera_data.zip\n",
            "total 13072\n",
            "drwxr-xr-x 2 root root   4096 Sep 27 08:27  .\n",
            "drwxr-xr-x 4 root root   4096 Mar 13  2017  ..\n",
            "-rw-r--r-- 1 root root  46706 Mar 13  2017  0013035.jpg\n",
            "-rw-r--r-- 1 root root 174618 Mar 13  2017  1030023514_aad5c608f9.jpg\n",
            "-rw-r--r-- 1 root root 126867 Mar 13  2017  1095476100_3906d8afde.jpg\n",
            "-rw-r--r-- 1 root root  74013 Mar 13  2017  1099452230_d1949d3250.jpg\n",
            "-rw-r--r-- 1 root root 143363 Mar 13  2017  116570827_e9c126745d.jpg\n",
            "-rw-r--r-- 1 root root  68516 Mar 13  2017  1225872729_6f0856588f.jpg\n",
            "-rw-r--r-- 1 root root  92614 Mar 13  2017  1262877379_64fcada201.jpg\n",
            "-rw-r--r-- 1 root root  58536 Mar 13  2017  1269756697_0bce92cdab.jpg\n",
            "-rw-r--r-- 1 root root 101735 Mar 13  2017  1286984635_5119e80de1.jpg\n",
            "-rw-r--r-- 1 root root 113608 Mar 13  2017  132478121_2a430adea2.jpg\n",
            "-rw-r--r-- 1 root root 142525 Mar 13  2017  1360291657_dc248c5eea.jpg\n",
            "-rw-r--r-- 1 root root  90708 Mar 13  2017  1368913450_e146e2fb6d.jpg\n",
            "-rw-r--r-- 1 root root 152727 Mar 13  2017  1473187633_63ccaacea6.jpg\n",
            "-rw-r--r-- 1 root root 102458 Mar 13  2017  148715752_302c84f5a4.jpg\n",
            "-rw-r--r-- 1 root root 107146 Mar 13  2017  1489674356_09d48dde0a.jpg\n",
            "-rw-r--r-- 1 root root 109471 Mar 13  2017  149244013_c529578289.jpg\n",
            "-rw-r--r-- 1 root root 168450 Mar 13  2017  150801003_3390b73135.jpg\n",
            "-rw-r--r-- 1 root root 158824 Mar 13  2017  150801171_cd86f17ed8.jpg\n",
            "-rw-r--r-- 1 root root 106352 Mar 13  2017  154124431_65460430f2.jpg\n",
            "-rw-r--r-- 1 root root  58731 Mar 13  2017  162603798_40b51f1654.jpg\n",
            "-rw-r--r-- 1 root root 167789 Mar 13  2017  1660097129_384bf54490.jpg\n",
            "-rw-r--r-- 1 root root 166219 Mar 13  2017  167890289_dd5ba923f3.jpg\n",
            "-rw-r--r-- 1 root root  74685 Mar 13  2017  1693954099_46d4c20605.jpg\n",
            "-rw-r--r-- 1 root root  49976 Mar 13  2017  175998972.jpg\n",
            "-rw-r--r-- 1 root root  90189 Mar 13  2017  178538489_bec7649292.jpg\n",
            "-rw-r--r-- 1 root root  29241 Mar 13  2017  1804095607_0341701e1c.jpg\n",
            "-rw-r--r-- 1 root root 114212 Mar 13  2017  1808777855_2a895621d7.jpg\n",
            "-rw-r--r-- 1 root root 195466 Mar 13  2017  188552436_605cc9b36b.jpg\n",
            "-rw-r--r-- 1 root root 102469 Mar 13  2017  1917341202_d00a7f9af5.jpg\n",
            "-rw-r--r-- 1 root root  80594 Mar 13  2017  1924473702_daa9aacdbe.jpg\n",
            "-rw-r--r-- 1 root root 131243 Mar 13  2017  196057951_63bf063b92.jpg\n",
            "-rw-r--r-- 1 root root 178227 Mar 13  2017  196757565_326437f5fe.jpg\n",
            "-rw-r--r-- 1 root root  98150 Mar 13  2017  201558278_fe4caecc76.jpg\n",
            "-rw-r--r-- 1 root root 137297 Mar 13  2017  201790779_527f4c0168.jpg\n",
            "-rw-r--r-- 1 root root  93077 Mar 13  2017  2019439677_2db655d361.jpg\n",
            "-rw-r--r-- 1 root root 190241 Mar 13  2017  207947948_3ab29d7207.jpg\n",
            "-rw-r--r-- 1 root root  41276 Mar 13  2017  20935278_9190345f6b.jpg\n",
            "-rw-r--r-- 1 root root  70249 Mar 13  2017  224655713_3956f7d39a.jpg\n",
            "-rw-r--r-- 1 root root 138801 Mar 13  2017  2265824718_2c96f485da.jpg\n",
            "-rw-r--r-- 1 root root 106689 Mar 13  2017  2265825502_fff99cfd2d.jpg\n",
            "-rw-r--r-- 1 root root 213051 Mar 13  2017  226951206_d6bf946504.jpg\n",
            "-rw-r--r-- 1 root root 139001 Mar 13  2017  2278278459_6b99605e50.jpg\n",
            "-rw-r--r-- 1 root root 112220 Mar 13  2017  2288450226_a6e96e8fdf.jpg\n",
            "-rw-r--r-- 1 root root 130163 Mar 13  2017  2288481644_83ff7e4572.jpg\n",
            "-rw-r--r-- 1 root root 145119 Mar 13  2017  2292213964_ca51ce4bef.jpg\n",
            "-rw-r--r-- 1 root root  39260 Mar 13  2017  24335309_c5ea483bb8.jpg\n",
            "-rw-r--r-- 1 root root  68087 Mar 13  2017  245647475_9523dfd13e.jpg\n",
            "-rw-r--r-- 1 root root  73251 Mar 13  2017  255434217_1b2b3fe0a4.jpg\n",
            "-rw-r--r-- 1 root root  96305 Mar 13  2017  258217966_d9d90d18d3.jpg\n",
            "-rw-r--r-- 1 root root 108213 Mar 13  2017  275429470_b2d7d9290b.jpg\n",
            "-rw-r--r-- 1 root root  62643 Mar 13  2017  28847243_e79fe052cd.jpg\n",
            "-rw-r--r-- 1 root root 196154 Mar 13  2017  318052216_84dff3f98a.jpg\n",
            "-rw-r--r-- 1 root root  95064 Mar 13  2017  334167043_cbd1adaeb9.jpg\n",
            "-rw-r--r-- 1 root root 222691 Mar 13  2017  339670531_94b75ae47a.jpg\n",
            "-rw-r--r-- 1 root root  78262 Mar 13  2017  342438950_a3da61deab.jpg\n",
            "-rw-r--r-- 1 root root  19292 Mar 13  2017  36439863_0bec9f554f.jpg\n",
            "-rw-r--r-- 1 root root 187853 Mar 13  2017  374435068_7eee412ec4.jpg\n",
            "-rw-r--r-- 1 root root 119876 Mar 13  2017  382971067_0bfd33afe0.jpg\n",
            "-rw-r--r-- 1 root root 145719 Mar 13  2017  384191229_5779cf591b.jpg\n",
            "-rw-r--r-- 1 root root 155365 Mar 13  2017  386190770_672743c9a7.jpg\n",
            "-rw-r--r-- 1 root root  81869 Mar 13  2017  392382602_1b7bed32fa.jpg\n",
            "-rw-r--r-- 1 root root  49103 Mar 13  2017  403746349_71384f5b58.jpg\n",
            "-rw-r--r-- 1 root root 108835 Mar 13  2017  408393566_b5b694119b.jpg\n",
            "-rw-r--r-- 1 root root 116506 Mar 13  2017  424119020_6d57481dab.jpg\n",
            "-rw-r--r-- 1 root root 126427 Mar 13  2017  424873399_47658a91fb.jpg\n",
            "-rw-r--r-- 1 root root 152377 Mar 13  2017  450057712_771b3bfc91.jpg\n",
            "-rw-r--r-- 1 root root 154973 Mar 13  2017  45472593_bfd624f8dc.jpg\n",
            "-rw-r--r-- 1 root root 166461 Mar 13  2017  459694881_ac657d3187.jpg\n",
            "-rw-r--r-- 1 root root  98436 Mar 13  2017  460372577_f2f6a8c9fc.jpg\n",
            "-rw-r--r-- 1 root root 190566 Mar 13  2017  460874319_0a45ab4d05.jpg\n",
            "-rw-r--r-- 1 root root 161335 Mar 13  2017  466430434_4000737de9.jpg\n",
            "-rw-r--r-- 1 root root  99375 Mar 13  2017  470127037_513711fd21.jpg\n",
            "-rw-r--r-- 1 root root 120752 Mar 13  2017  474806473_ca6caab245.jpg\n",
            "-rw-r--r-- 1 root root 104098 Mar 13  2017  475961153_b8c13fd405.jpg\n",
            "-rw-r--r-- 1 root root 173699 Mar 13  2017  484293231_e53cfc0c89.jpg\n",
            "-rw-r--r-- 1 root root  79679 Mar 13  2017  49375974_e28ba6f17e.jpg\n",
            "-rw-r--r-- 1 root root 100910 Mar 13  2017  506249802_207cd979b4.jpg\n",
            "-rw-r--r-- 1 root root 109181 Mar 13  2017  506249836_717b73f540.jpg\n",
            "-rw-r--r-- 1 root root 127009 Mar 13  2017  512164029_c0a66b8498.jpg\n",
            "-rw-r--r-- 1 root root 148586 Mar 13  2017  512863248_43c8ce579b.jpg\n",
            "-rw-r--r-- 1 root root 111442 Mar 13  2017  518773929_734dbc5ff4.jpg\n",
            "-rw-r--r-- 1 root root  44929 Mar 13  2017  522163566_fec115ca66.jpg\n",
            "-rw-r--r-- 1 root root 117142 Mar 13  2017  522415432_2218f34bf8.jpg\n",
            "-rw-r--r-- 1 root root 123102 Mar 13  2017  531979952_bde12b3bc0.jpg\n",
            "-rw-r--r-- 1 root root 105853 Mar 13  2017  533848102_70a85ad6dd.jpg\n",
            "-rw-r--r-- 1 root root  62678 Mar 13  2017  535522953_308353a07c.jpg\n",
            "-rw-r--r-- 1 root root  86631 Mar 13  2017  540889389_48bb588b21.jpg\n",
            "-rw-r--r-- 1 root root 104297 Mar 13  2017  541630764_dbd285d63c.jpg\n",
            "-rw-r--r-- 1 root root  95746 Mar 13  2017  543417860_b14237f569.jpg\n",
            "-rw-r--r-- 1 root root  69920 Mar 13  2017  560966032_988f4d7bc4.jpg\n",
            "-rw-r--r-- 1 root root  28547 Mar 13  2017  5650366_e22b7e1065.jpg\n",
            "-rw-r--r-- 1 root root  34021 Mar 13  2017  6240329_72c01e663e.jpg\n",
            "-rw-r--r-- 1 root root  19117 Mar 13  2017  6240338_93729615ec.jpg\n",
            "-rw-r--r-- 1 root root 141417 Mar 13  2017  649026570_e58656104b.jpg\n",
            "-rw-r--r-- 1 root root  86399 Mar 13  2017  662541407_ff8db781e7.jpg\n",
            "-rw-r--r-- 1 root root 115875 Mar 13  2017  67270775_e9fdf77e9d.jpg\n",
            "-rw-r--r-- 1 root root  88429 Mar 13  2017  6743948_2b8c096dda.jpg\n",
            "-rw-r--r-- 1 root root  48503 Mar 13  2017  684133190_35b62c0c1d.jpg\n",
            "-rw-r--r-- 1 root root  81892 Mar 13  2017  69639610_95e0de17aa.jpg\n",
            "-rw-r--r-- 1 root root 108884 Mar 13  2017  707895295_009cf23188.jpg\n",
            "-rw-r--r-- 1 root root  17422 Mar 13  2017  7759525_1363d24e88.jpg\n",
            "-rw-r--r-- 1 root root 113884 Mar 13  2017  795000156_a9900a4a71.jpg\n",
            "-rw-r--r-- 1 root root 118016 Mar 13  2017  822537660_caf4ba5514.jpg\n",
            "-rw-r--r-- 1 root root 111349 Mar 13  2017  82852639_52b7f7f5e3.jpg\n",
            "-rw-r--r-- 1 root root  71194 Mar 13  2017  841049277_b28e58ad05.jpg\n",
            "-rw-r--r-- 1 root root 112947 Mar 13  2017  886401651_f878e888cd.jpg\n",
            "-rw-r--r-- 1 root root 143387 Mar 13  2017  892108839_f1aad4ca46.jpg\n",
            "-rw-r--r-- 1 root root 113652 Mar 13  2017  938946700_ca1c669085.jpg\n",
            "-rw-r--r-- 1 root root 143558 Mar 13  2017  957233405_25c1d1187b.jpg\n",
            "-rw-r--r-- 1 root root  39364 Mar 13  2017  9715481_b3cb4114ff.jpg\n",
            "-rw-r--r-- 1 root root  93208 Mar 13  2017  998118368_6ac1d91f81.jpg\n",
            "-rw-r--r-- 1 root root  18839 Mar 13  2017  Ant_1.jpg\n",
            "-rw-r--r-- 1 root root  29645 Mar 13  2017 'ant photos.jpg'\n",
            "-rw-r--r-- 1 root root  19821 Mar 13  2017  army-ants-red-picture.jpg\n",
            "-rw-r--r-- 1 root root   7858 Mar 13  2017  formica.jpeg\n",
            "-rw-r--r-- 1 root root  34026 Mar 13  2017  hormiga_co_por.jpg\n",
            "-rw-r--r-- 1 root root   5504 Mar 13  2017  imageNotFound.gif\n",
            "-rw-r--r-- 1 root root  24140 Mar 13  2017  kurokusa.jpg\n",
            "-rw-r--r-- 1 root root  81416 Mar 13  2017  MehdiabadiAnt2_600.jpg\n",
            "-rw-r--r-- 1 root root 710225 Mar 13  2017  Nepenthes_rafflesiana_ant.jpg\n",
            "-rw-r--r-- 1 root root  16013 Mar 13  2017  swiss-army-ant.jpg\n",
            "-rw-r--r-- 1 root root  23477 Mar 13  2017  termite-vs-ant.jpg\n",
            "-rw-r--r-- 1 root root   7808 Mar 13  2017  trap-jaw-ant-insect-bg.jpg\n",
            "-rw-r--r-- 1 root root  63372 Mar 13  2017  VietnameseAntMimicSpider.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCHsqKxW1Ax0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#各種パラメータを初期化します。\n",
        "#model_nameで指定するモデルは以下の著名なものの中から選びます\n",
        "# [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "\n",
        "# Top level data directory. Here we assume the format of the directory conforms\n",
        "#   to the ImageFolder structure\n",
        "data_dir = \"./data/hymenoptera_data\"\n",
        "\n",
        "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"squeezenet\"\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 2\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "num_epochs = 15\n",
        "\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UN3aQRs2p1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#学習と検証を行う関数を用意しておく\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPedq4tA2w0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feature extracingでは初期化された層のみ計算したいので、他層は勾配追跡をOFFにする\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAXyb9Iu3du8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1e2aff0-6c6b-4560-d48a-00dd3378d1ce"
      },
      "source": [
        "#モデルの初期化ヘルパ\n",
        "#事前訓練済みモデル種別に応じて適宜設定する\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract) #feature_extract:FalseのときFineTuning(全パラメータ更新)動作\n",
        "        #事前訓練済みモデル最終層を新規学習用に差し替え。入力チャンネル数は事前訓練済みモデルと揃える\n",
        "        #差し替える層の名前はモデルで異なる\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "# Print the model we just instantiated\n",
        "print(model_ft)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5)\n",
            "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace)\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awIrYAhT9CkX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ab32d84-1fba-4220-e0c4-8a8452d13a29"
      },
      "source": [
        "#データロード\n",
        "# Data augmentation and normalization for training\n",
        "# Just normalization for validation\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create training and validation datasets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "# Create training and validation dataloaders\n",
        "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "# Detect if we have a GPU available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C0eP9bj9S60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "246cf694-db80-42de-9606-be433f1502d8"
      },
      "source": [
        "#最適化関数の用意\n",
        "#feature_extract:Trueのとき、対象は最終層パラメータのみのはず\n",
        "\n",
        "# Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Params to learn:\n",
            "\t features.0.weight\n",
            "\t features.0.bias\n",
            "\t features.3.squeeze.weight\n",
            "\t features.3.squeeze.bias\n",
            "\t features.3.expand1x1.weight\n",
            "\t features.3.expand1x1.bias\n",
            "\t features.3.expand3x3.weight\n",
            "\t features.3.expand3x3.bias\n",
            "\t features.4.squeeze.weight\n",
            "\t features.4.squeeze.bias\n",
            "\t features.4.expand1x1.weight\n",
            "\t features.4.expand1x1.bias\n",
            "\t features.4.expand3x3.weight\n",
            "\t features.4.expand3x3.bias\n",
            "\t features.5.squeeze.weight\n",
            "\t features.5.squeeze.bias\n",
            "\t features.5.expand1x1.weight\n",
            "\t features.5.expand1x1.bias\n",
            "\t features.5.expand3x3.weight\n",
            "\t features.5.expand3x3.bias\n",
            "\t features.7.squeeze.weight\n",
            "\t features.7.squeeze.bias\n",
            "\t features.7.expand1x1.weight\n",
            "\t features.7.expand1x1.bias\n",
            "\t features.7.expand3x3.weight\n",
            "\t features.7.expand3x3.bias\n",
            "\t features.8.squeeze.weight\n",
            "\t features.8.squeeze.bias\n",
            "\t features.8.expand1x1.weight\n",
            "\t features.8.expand1x1.bias\n",
            "\t features.8.expand3x3.weight\n",
            "\t features.8.expand3x3.bias\n",
            "\t features.9.squeeze.weight\n",
            "\t features.9.squeeze.bias\n",
            "\t features.9.expand1x1.weight\n",
            "\t features.9.expand1x1.bias\n",
            "\t features.9.expand3x3.weight\n",
            "\t features.9.expand3x3.bias\n",
            "\t features.10.squeeze.weight\n",
            "\t features.10.squeeze.bias\n",
            "\t features.10.expand1x1.weight\n",
            "\t features.10.expand1x1.bias\n",
            "\t features.10.expand3x3.weight\n",
            "\t features.10.expand3x3.bias\n",
            "\t features.12.squeeze.weight\n",
            "\t features.12.squeeze.bias\n",
            "\t features.12.expand1x1.weight\n",
            "\t features.12.expand1x1.bias\n",
            "\t features.12.expand3x3.weight\n",
            "\t features.12.expand3x3.bias\n",
            "\t classifier.1.weight\n",
            "\t classifier.1.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g9_GagV-AQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#損失関数の用意\n",
        "# Setup the loss fxn\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mn1YGzi-FIg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f770879-6309-4234-c012-5bd96217eceb"
      },
      "source": [
        "#学習と検証の実行\n",
        "# Train and evaluate\n",
        "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.5733 Acc: 0.7131\n",
            "val Loss: 0.5373 Acc: 0.7516\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.4761 Acc: 0.7787\n",
            "val Loss: 0.3271 Acc: 0.9020\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.3627 Acc: 0.8279\n",
            "val Loss: 0.3302 Acc: 0.8627\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.2911 Acc: 0.8730\n",
            "val Loss: 0.4465 Acc: 0.7647\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.3381 Acc: 0.8934\n",
            "val Loss: 0.3114 Acc: 0.9020\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.2837 Acc: 0.8648\n",
            "val Loss: 0.4422 Acc: 0.8235\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.2666 Acc: 0.8730\n",
            "val Loss: 0.2984 Acc: 0.9085\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.3249 Acc: 0.8730\n",
            "val Loss: 0.3602 Acc: 0.8758\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.2473 Acc: 0.8730\n",
            "val Loss: 0.5499 Acc: 0.7778\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.2483 Acc: 0.8975\n",
            "val Loss: 0.4915 Acc: 0.8235\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.2190 Acc: 0.9262\n",
            "val Loss: 0.5558 Acc: 0.7712\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.1682 Acc: 0.9262\n",
            "val Loss: 0.4448 Acc: 0.8758\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.4299 Acc: 0.8197\n",
            "val Loss: 0.6034 Acc: 0.6993\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.5004 Acc: 0.7377\n",
            "val Loss: 0.4562 Acc: 0.8301\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.3645 Acc: 0.8115\n",
            "val Loss: 0.4493 Acc: 0.8758\n",
            "\n",
            "Training complete in 1m 4s\n",
            "Best val Acc: 0.908497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHodobTY-cuF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "99f23d2b-8af8-433c-96a7-1848a0e9069f"
      },
      "source": [
        "#事前学習データをセットしていないモデルで少数データで学習させて、比較\n",
        "# Initialize the non-pretrained version of the model used for this run\n",
        "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
        "scratch_model = scratch_model.to(device)\n",
        "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
        "scratch_criterion = nn.CrossEntropyLoss()\n",
        "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
        "\n",
        "# Plot the training curves of validation accuracy vs. number\n",
        "#  of training epochs for the transfer learning method and\n",
        "#  the model trained from scratch\n",
        "ohist = []\n",
        "shist = []\n",
        "\n",
        "ohist = [h.cpu().numpy() for h in hist]\n",
        "shist = [h.cpu().numpy() for h in scratch_hist]\n",
        "\n",
        "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Validation Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
        "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
        "plt.ylim((0,1.))\n",
        "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/14\n",
            "----------\n",
            "train Loss: 0.6990 Acc: 0.4795\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 1/14\n",
            "----------\n",
            "train Loss: 0.6917 Acc: 0.5123\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 2/14\n",
            "----------\n",
            "train Loss: 0.6917 Acc: 0.4959\n",
            "val Loss: 0.6931 Acc: 0.4902\n",
            "\n",
            "Epoch 3/14\n",
            "----------\n",
            "train Loss: 0.6840 Acc: 0.4959\n",
            "val Loss: 0.6924 Acc: 0.5294\n",
            "\n",
            "Epoch 4/14\n",
            "----------\n",
            "train Loss: 0.6862 Acc: 0.4959\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 5/14\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 6/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5082\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 7/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 8/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 9/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 10/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5082\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 11/14\n",
            "----------\n",
            "train Loss: 0.6931 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 12/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5041\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 13/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5000\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Epoch 14/14\n",
            "----------\n",
            "train Loss: 0.6932 Acc: 0.5000\n",
            "val Loss: 0.6931 Acc: 0.4575\n",
            "\n",
            "Training complete in 1m 3s\n",
            "Best val Acc: 0.529412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}